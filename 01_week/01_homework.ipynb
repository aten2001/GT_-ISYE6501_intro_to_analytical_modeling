{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(kernlab)\n",
    "library(glue)\n",
    "library(kknn)\n",
    "\n",
    "set.seed(42)\n",
    "### sink() is just used to hide a few warning messages in order to tidy up the code.\n",
    "sink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1\n",
    "\n",
    "Describe a situation or problem from your job, everyday life, current events, etc., for which a\n",
    "classification model would be appropriate. List some (up to 5) predictors that you might use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "\n",
    "After a bit of thinking, I came to the conclusion that most of my life can fit a binary classification model. For example, a common situation that occurs day-to-day is my decision to either snooze my alarm or not snooze my alarm. Five predictors that determine the outcome of this event are:\n",
    "\n",
    "1. How many hours did I sleep last night?\n",
    "2. Is it the weekend or a weekday?\n",
    "3. Do I have a meeting I cannot be late for?\n",
    "4. Did I go out drinking last night?\n",
    "5. Was yesterday an especially tiring day?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2\n",
    "\n",
    "The files credit_card_data.txt (without headers) and credit_card_data-headers.txt\n",
    "(with headers) contain a dataset with 654 data points, 6 continuous and 4 binary predictor variables. It\n",
    "has anonymized credit card applications with a binary response variable (last column) indicating if the\n",
    "application was positive or negative. The dataset is the “Credit Approval Data Set” from the UCI Machine\n",
    "Learning Repository (https://archive.ics.uci.edu/ml/datasets/Credit+Approval) without the categorical\n",
    "variables and without data points that have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_data <- read.delim(\"../data/2.2credit_card_data-headersSummer2018.txt\")\n",
    "\n",
    "# Separating the data into predictors and response variable\n",
    "X <- select(cc_data, -R1)\n",
    "y <- select(cc_data, R1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 has 0 nulls\n",
      "A2 has 0 nulls\n",
      "A3 has 0 nulls\n",
      "A8 has 0 nulls\n",
      "A9 has 0 nulls\n",
      "A10 has 0 nulls\n",
      "A11 has 0 nulls\n",
      "A12 has 0 nulls\n",
      "A14 has 0 nulls\n",
      "A15 has 0 nulls\n",
      "R1 has 0 nulls\n"
     ]
    }
   ],
   "source": [
    "# Check for null values\n",
    "for (col in colnames(cc_data)) {\n",
    "    num_nulls  <- sum(is.na(cc_data$R1))\n",
    "    print(glue(\"{col} has {num_nulls} nulls\"))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Using the support vector machine function ksvm contained in the R package kernlab, find a good classifier for this data. Show the equation of your classifier, and how well it classifies the data points in the full data set. (Don’t worry about test/validation data yet; we’ll cover that topic soon.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n"
     ]
    }
   ],
   "source": [
    "svm <- ksvm(x=as.matrix(X), \n",
    "            y=y, \n",
    "            scaled=TRUE, \n",
    "            type=\"C-svc\", \n",
    "            kernel=\"tanhdot\", \n",
    "            C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         A1          A2          A3          A8          A9         A10 \n",
      " 1609.69254  -606.89291   -74.03735   869.13373  3916.09987     0.00000 \n",
      "        A11         A12         A14         A15 \n",
      " 2096.27745 -1092.97383   269.42655  1836.96432 \n"
     ]
    }
   ],
   "source": [
    "# Getting the coefficients for each predictor\n",
    "a <- colSums(svm@xmatrix[[1]] * svm@coef[[1]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a0 is -80.0872690537478\n"
     ]
    }
   ],
   "source": [
    "a0 <- svm@b\n",
    "print(glue(\"a0 is {a0}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SVM Model was correct 72.171% of the time\n"
     ]
    }
   ],
   "source": [
    "pred <- predict(svm, X)\n",
    "\n",
    "acc <- round(sum(pred == y) / nrow(X) * 100, digits=3)\n",
    "print(glue(\"The SVM Model was correct {acc}% of the time\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### UDF for getting accuracy of SVM model\n",
    "get_svm_metadata <- function(X, y, model) {\n",
    "    coefs <- colSums(model@xmatrix[[1]] * model@coef[[1]])\n",
    "    a0 <- model@b\n",
    "    predictions <- predict(model, X)\n",
    "    accuracy <- round(sum(predictions == y) / nrow(X) * 100, digits=3)\n",
    "    \n",
    "#     print(coefs)\n",
    "#     print(glue(\"a0 is {a0}\"))\n",
    "    print(glue(\"The SVM Model was correct {accuracy}% of the time\"))\n",
    "    return(list(coefs=coefs, a0=a0, pred=predictions, acc=accuracy))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n",
      "C value is 0.001\n",
      "The SVM Model was correct 83.792% of the time\n",
      " Setting default kernel parameters  \n",
      "C value is 0.01\n",
      "The SVM Model was correct 86.391% of the time\n",
      " Setting default kernel parameters  \n",
      "C value is 0.1\n",
      "The SVM Model was correct 86.391% of the time\n",
      " Setting default kernel parameters  \n",
      "C value is 1\n",
      "The SVM Model was correct 86.391% of the time\n",
      " Setting default kernel parameters  \n",
      "C value is 10\n",
      "The SVM Model was correct 86.391% of the time\n",
      " Setting default kernel parameters  \n",
      "C value is 100\n",
      "The SVM Model was correct 86.391% of the time\n",
      " Setting default kernel parameters  \n",
      "C value is 1000\n",
      "The SVM Model was correct 86.239% of the time\n"
     ]
    }
   ],
   "source": [
    "### TRY THIS FOR OTHER VALUES OF C\n",
    "c_list <- c(0.001, 0.01, 0.1, 1, 10, 100, 1000)\n",
    "\n",
    "for (c in c_list) {\n",
    "    temp_model <- ksvm(x=as.matrix(X), \n",
    "                       y=y, \n",
    "                       scaled=TRUE, \n",
    "                       type=\"C-svc\", \n",
    "                       kernel=\"vanilladot\", \n",
    "                       C=c)\n",
    "    print(glue(\"C value is {c}\"))\n",
    "    metadata_list <- get_svm_metadata(X, y, temp_model)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the linear kernel it seems that the SVM model with a C value of 0.01, 0.1, 1, 10 or 100 would provide the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. You are welcome, but not required, to try other (nonlinear) kernels as well; we’re not covering them in this course, but they can sometimes be useful and might provide better predictions than vanilladot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value is 0.001\n",
      "The SVM Model was correct 54.74% of the time\n",
      "C value is 0.01\n",
      "The SVM Model was correct 56.728% of the time\n",
      "C value is 0.1\n",
      "The SVM Model was correct 85.933% of the time\n",
      "C value is 1\n",
      "The SVM Model was correct 87.003% of the time\n",
      "C value is 10\n",
      "The SVM Model was correct 90.979% of the time\n",
      "C value is 100\n",
      "The SVM Model was correct 96.024% of the time\n",
      "C value is 1000\n",
      "The SVM Model was correct 98.012% of the time\n"
     ]
    }
   ],
   "source": [
    "### Radial Basis Kernel\n",
    "c_list <- c(0.001, 0.01, 0.1, 1, 10, 100, 1000)\n",
    "\n",
    "for (c in c_list) {\n",
    "    temp_model <- ksvm(x=as.matrix(X), \n",
    "                       y=y, \n",
    "                       scaled=TRUE, \n",
    "                       type=\"C-svc\", \n",
    "                       kernel=\"rbfdot\", \n",
    "                       C=c)\n",
    "    print(glue(\"C value is {c}\"))\n",
    "    metadata_list <- get_svm_metadata(X, y, temp_model)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the RBF kernel, the model with a C value of 1000 provided the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n",
      "C value is 0.001\n",
      "The SVM Model was correct 83.792% of the time\n",
      " Setting default kernel parameters  \n",
      "C value is 0.01\n",
      "The SVM Model was correct 86.391% of the time\n",
      " Setting default kernel parameters  \n",
      "C value is 0.1\n",
      "The SVM Model was correct 86.391% of the time\n",
      " Setting default kernel parameters  \n",
      "C value is 1\n",
      "The SVM Model was correct 86.391% of the time\n",
      " Setting default kernel parameters  \n",
      "C value is 10\n",
      "The SVM Model was correct 86.391% of the time\n",
      " Setting default kernel parameters  \n",
      "C value is 100\n",
      "The SVM Model was correct 86.391% of the time\n",
      " Setting default kernel parameters  \n",
      "C value is 1000\n",
      "The SVM Model was correct 86.239% of the time\n"
     ]
    }
   ],
   "source": [
    "### Polynomial kernel\n",
    "c_list <- c(0.001, 0.01, 0.1, 1, 10, 100, 1000)\n",
    "\n",
    "for (c in c_list) {\n",
    "    temp_model <- ksvm(x=as.matrix(X), \n",
    "                       y=y, \n",
    "                       scaled=TRUE, \n",
    "                       type=\"C-svc\", \n",
    "                       kernel=\"polydot\", \n",
    "                       C=c)\n",
    "    print(glue(\"C value is {c}\"))\n",
    "    metadata_list <- get_svm_metadata(X, y, temp_model)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the polynomial kernel, the results are similar to the linear kernel where the best model is the one with a C value of 0.01, 0.1, 1, 10, or 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Using the k-nearest-neighbors classification function kknn contained in the R kknn package, suggest a good value of k, and show how well it classifies that data points in the full data set. Don’t forget to scale the data (scale=TRUE in kknn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "train.kknn(formula = as.factor(R1) ~ ., data = cc_data, kmax = 100,     distance = 2, kernel = \"optimal\", scale = TRUE)\n",
       "\n",
       "Type of response variable: nominal\n",
       "Minimal misclassification: 0.146789\n",
       "Best kernel: optimal\n",
       "Best k: 12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit <- train.kknn(formula=as.factor(R1)~., \n",
    "                  data=cc_data, \n",
    "                  kmax=100, \n",
    "                  distance=2, \n",
    "                  kernel=\"optimal\", \n",
    "                  scale=TRUE)\n",
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k value of 12, the accuracy was 91.59%\n"
     ]
    }
   ],
   "source": [
    "predictions <- predict(fit, cc_data)\n",
    "\n",
    "accuracy <- round(sum(predictions == cc_data$R1) / nrow(cc_data) * 100, digits=3)\n",
    "print(glue(\"For k value of 12, the accuracy was {accuracy}%\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The best performing model uses a k value of 12 and has a accuracy of 91.59%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.1\n",
    "\n",
    "Using the same data set (credit_card_data.txt or credit_card_data-headers.txt) as\n",
    "in Question 2.2, use the ksvm or kknn function to find a good classifier:\n",
    "\n",
    "**(a) using cross-validation (do this for the k-nearest-neighbors model; SVM is optional); and**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1\n",
      "Model accuracy is 64.122%\n",
      "Iteration #2\n",
      "Model accuracy is 83.206%\n",
      "Iteration #3\n",
      "Model accuracy is 93.077%\n",
      "Iteration #4\n",
      "Model accuracy is 83.969%\n",
      "Iteration #5\n",
      "Model accuracy is 89.313%\n"
     ]
    }
   ],
   "source": [
    "# Shuffle data\n",
    "shuffled_df <- cc_data[sample(nrow(cc_data)), ]\n",
    "\n",
    "# 5 fold split\n",
    "folds <- cut(seq(1, nrow(cc_data)), breaks=5, labels=FALSE)\n",
    "\n",
    "# For each fold, train and test on KNN algorithm\n",
    "for (i in 1:5) {\n",
    "    print(glue(\"Iteration #{i}\"))\n",
    "    test_indices <- which(folds==i, arr.ind=TRUE)\n",
    "    test_data <- cc_data[test_indices, ]\n",
    "    train_data <- cc_data[-test_indices, ]\n",
    "    \n",
    "    # ks=12 was chosen since that was the best k value given from running the KNN algorithm on the entire data set\n",
    "    temp_fit <- train.kknn(formula=as.factor(R1)~., \n",
    "                           data=train_data, \n",
    "                           ks=12, \n",
    "                           distance=2, \n",
    "                           kernel=\"optimal\", \n",
    "                           scale=TRUE)\n",
    "    \n",
    "    # Perform prediction step on test data since model was fit using the training data\n",
    "    temp_pred <- predict(temp_fit, test_data)    \n",
    "    temp_accuracy <- round(sum(temp_pred == test_data$R1) / nrow(test_data) * 100, digits=3)\n",
    "    print(glue(\"Model accuracy is {temp_accuracy}%\"))\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) splitting the data into training, validation, and test data sets (pick either KNN or SVM; the other is optional).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows for training set: 327 (50%)\n",
      "Number of rows for validate set: 164 (25.1%)\n",
      "Number of rows for test set: 163 (24.9%)\n"
     ]
    }
   ],
   "source": [
    "spec <- c(train=0.5, test=0.25, validate=0.25)\n",
    "\n",
    "# Breaking down this line of code below:\n",
    "## seq(nrow(cc_data)) gets the row indices\n",
    "## nrow(cc_data)*cumsum(c(0,spec)) gets the number of rows that belong to each set of data\n",
    "## labels=names(spec) labels each row of data as either train, test, or validate\n",
    "## The cut() function takes the row indices and splits the data into 3 groups\n",
    "## The sample() function randomly shuffles the data\n",
    "splits <- sample(cut(seq(nrow(cc_data)), nrow(cc_data)*cumsum(c(0,spec)), labels=names(spec)))\n",
    "\n",
    "sets <- split(cc_data, splits)\n",
    "\n",
    "# Confirm that the sizes of each set are correct\n",
    "nrow_train <- nrow(sets$train)\n",
    "perc_train <- round(nrow_train / nrow(cc_data)*100, digits=1)\n",
    "\n",
    "nrow_validate <- nrow(sets$validate)\n",
    "perc_validate <- round(nrow_validate / nrow(cc_data)*100, digits=1)\n",
    "\n",
    "nrow_test <- nrow(sets$test)\n",
    "perc_test <- round(nrow_test / nrow(cc_data)*100, digits=1)\n",
    "\n",
    "print(glue(\"Number of rows for training set: {nrow_train} ({perc_train}%)\"))\n",
    "print(glue(\"Number of rows for validate set: {nrow_validate} ({perc_validate}%)\"))\n",
    "print(glue(\"Number of rows for test set: {nrow_test} ({perc_test}%)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy is 84.146% for k = 5\n",
      "Model accuracy is 84.146% for k = 15\n",
      "Model accuracy is 84.756% for k = 25\n",
      "Model accuracy is 84.756% for k = 35\n",
      "Model accuracy is 85.366% for k = 45\n",
      "Model accuracy is 85.366% for k = 55\n",
      "Model accuracy is 84.146% for k = 65\n",
      "Model accuracy is 85.976% for k = 75\n",
      "Model accuracy is 87.805% for k = 85\n",
      "Model accuracy is 87.195% for k = 95\n",
      "Model accuracy is 86.585% for k = 105\n"
     ]
    }
   ],
   "source": [
    "for (i in seq(from=5, to=105, by=10)) {\n",
    "    temp_fit <- train.kknn(formula=as.factor(R1)~., \n",
    "                           data=sets$train, \n",
    "                           ks=i, \n",
    "                           distance=2, \n",
    "                           kernel=\"optimal\", \n",
    "                           scale=TRUE)\n",
    "    \n",
    "    # Perform prediction step on test data since model was fit using the training data\n",
    "    temp_pred <- predict(temp_fit, sets$validate)    \n",
    "    temp_accuracy <- round(sum(temp_pred == sets$validate$R1) / nrow(sets$validate) * 100, digits=3)\n",
    "    print(glue(\"Model accuracy is {temp_accuracy}% for k = {i}\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best model is the one with k = 85**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model accuracy is 83.436% for k = 85\n"
     ]
    }
   ],
   "source": [
    "final_model <- train.kknn(formula=as.factor(R1)~., \n",
    "                          data=sets$train, \n",
    "                          ks=85, \n",
    "                          distance=2, \n",
    "                          kernel=\"optimal\", \n",
    "                          scale=TRUE)\n",
    "test_pred <- predict(final_model, sets$test)\n",
    "\n",
    "test_accuracy <- round(sum(test_pred == sets$test$R1) / nrow(sets$test) * 100, digits=3)\n",
    "print(glue(\"Final model accuracy is {test_accuracy}% for k = 85\"))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
