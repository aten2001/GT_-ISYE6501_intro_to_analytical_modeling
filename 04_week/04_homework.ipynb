{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lattice\n",
      "Loading required package: ggplot2\n",
      "\n",
      "Attaching package: ‘ggplot2’\n",
      "\n",
      "The following object is masked from ‘package:randomForest’:\n",
      "\n",
      "    margin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(glue)\n",
    "library(rpart)\n",
    "library(RColorBrewer)\n",
    "library(randomForest)\n",
    "library(caret)\n",
    "\n",
    "options(repr.plot.width=10, repr.plot.height=5)\n",
    "\n",
    "set.seed(20)\n",
    "options(warn=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9.1\n",
    "\n",
    "**Using the same crime data set uscrime.txt as in Question 8.2, apply Principal Component Analysis and then create a regression model using the first few principal components. Specify your new model in terms of the original variables (not the principal components), and compare its quality to that of your solution to Question 8.2. You can use the R function prcomp for PCA. (Note that to first scale the data, you can include scale. = TRUE to scale as part of the PCA function. Don’t forget that, to make a prediction for the new city, you’ll need to unscale the coefficients (i.e., do the scaling calculation in reverse)!)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few helper functions I need in order to evaluate the regression models are defined first.\n",
    "\n",
    "The root mean squared error (RMSE) and the mean absolute error (MAE) functions are defined below. These functions will be used to understand the performance of the models. The lower the error the better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RMSE function\n",
    "rmse <- function(resids) {\n",
    "    sqrt(mean(resids^2))\n",
    "}\n",
    "# MAE function\n",
    "mae <- function(resids) {\n",
    "    mean(abs(resids))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is read in and defined as a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crime_data <- read.table('../data/9.1uscrimeSummer2018.txt', sep='', header=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample data that the final model is going to be used to predict on is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M  <-  14.0\n",
    "So <- 0\n",
    "Ed <- 10.0\n",
    "Po1 <- 12.0\n",
    "Po2 <- 15.5\n",
    "LF <- 0.640\n",
    "M.F <- 94.0\n",
    "Pop <- 150\n",
    "NW <- 1.1\n",
    "U1 <- 0.120\n",
    "U2 <- 3.6\n",
    "Wealth <- 3200\n",
    "Ineq <- 20.1\n",
    "Prob <- 0.04\n",
    "Time <- 39.0\n",
    "\n",
    "sample_data <- data.frame(M,So,Ed,Po1,Po2,LF,M.F,Pop,NW,U1,U2,Wealth,Ineq,Prob,Time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From homework 3 question 8.2, the best performing model I found had the following formula:\n",
    "\n",
    "Crime ~ M + Ed + Po1 + U2 + Ineq + Prob + Time\n",
    "\n",
    "The model from question 8.2 is defined and evaluated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the crime rate for the sample data is 1285.283\n",
      "[1] \"Model from Question 8.2\"\n",
      "\n",
      "Call:\n",
      "lm(formula = Crime ~ M + Ed + Po1 + U2 + Ineq + Prob + Time, \n",
      "    data = crime_data)\n",
      "\n",
      "Residuals:\n",
      "    Min      1Q  Median      3Q     Max \n",
      "-480.89  -89.12   -6.63  140.27  576.79 \n",
      "\n",
      "Coefficients:\n",
      "             Estimate Std. Error t value Pr(>|t|)    \n",
      "(Intercept) -4911.094    960.729  -5.112 8.79e-06 ***\n",
      "M             106.659     33.877   3.148 0.003144 ** \n",
      "Ed            189.408     48.288   3.922 0.000345 ***\n",
      "Po1           115.704     13.993   8.269 4.16e-10 ***\n",
      "U2             88.720     41.364   2.145 0.038249 *  \n",
      "Ineq           67.728     14.083   4.809 2.28e-05 ***\n",
      "Prob        -4249.756   1880.672  -2.260 0.029502 *  \n",
      "Time           -2.310      5.538  -0.417 0.678810    \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Residual standard error: 202.8 on 39 degrees of freedom\n",
      "Multiple R-squared:  0.7669,\tAdjusted R-squared:  0.7251 \n",
      "F-statistic: 18.33 on 7 and 39 DF,  p-value: 1.553e-10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_8 <- lm(formula=Crime ~ M + Ed + Po1 + U2 + Ineq + Prob + Time, data=crime_data)\n",
    "\n",
    "sample_prediction <- round(predict(model_8, sample_data), 3)\n",
    "\n",
    "print(glue(\"Prediction for the crime rate for the sample data is {sample_prediction}\"))\n",
    "print(\"Model from Question 8.2\")\n",
    "print(summary(model_8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model from 8.2 had an adjusted R-squared of 0.7251 and a residual standard error of 202.8. Also, the predicted crime rate for the fictional city was 1285.283. This will be the baseline to compare the PCA models too.\n",
    "\n",
    "Perform scaling and PCA on the crime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_crime <- prcomp(crime_data[,-16], scale=TRUE)\n",
    "\n",
    "# Grab just the transformed data\n",
    "pca_data <- pca_crime$x\n",
    "pca_data <- cbind(pca_data, Crime=crime_data$Crime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many components to use will be determined by testing a few different values. I'll use values between 3 and 6 components and evaluate each model with a 5 fold cross validation.\n",
    "\n",
    "In order to limit the amount of results shown, I will calculate the RMSE and MAE for each model and only for the best model will I show the summary of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Component PCA\n",
      "RMSE: 352.926\n",
      "MAE: 281.825\n",
      "4-Component PCA\n",
      "RMSE: 350.955\n",
      "MAE: 278.844\n",
      "5-Component PCA\n",
      "RMSE: 275.227\n",
      "MAE: 222.131\n",
      "6-Component PCA\n",
      "RMSE: 273.053\n",
      "MAE: 220.4\n"
     ]
    }
   ],
   "source": [
    "for (n in 3:6) {\n",
    "    # Shuffle data\n",
    "    shuffled_df <- pca_data[sample(nrow(pca_data)), c(1:n, 16)]\n",
    "\n",
    "    # 5 fold split\n",
    "    folds <- cut(seq(1, nrow(pca_data)), breaks=5, labels=FALSE)\n",
    "\n",
    "    # For each fold, train and test on Linear Regression algorithm\n",
    "    resids <- c(1:nrow(pca_data))\n",
    "    preds <- c(1:nrow(pca_data))\n",
    "    for (i in 1:5) {\n",
    "        test_indices <- which(folds==i, arr.ind=TRUE)\n",
    "        test_data <- as.data.frame(shuffled_df[test_indices, ])\n",
    "        train_data <- as.data.frame(shuffled_df[-test_indices, ])\n",
    "\n",
    "        temp_fit <- lm(formula=Crime ~., data=train_data)\n",
    "\n",
    "        # Perform prediction step on test data since model was fit using the training data\n",
    "        preds[test_indices] <- predict(temp_fit, test_data)    \n",
    "        resids[test_indices] <- test_data$Crime - preds[test_indices]\n",
    "    }\n",
    "\n",
    "    overall_rmse <- round(rmse(resids), 3)\n",
    "    overall_mae <- round(mae(resids), 3)\n",
    "    \n",
    "    print(glue(\"{n}-Component PCA\"))\n",
    "    print(glue(\"RMSE: {overall_rmse}\"))\n",
    "    print(glue(\"MAE: {overall_mae}\")) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the RMSE and MAE above, a 6-component PCA model is the best performing given a 5-fold CV. Using the full dataset, a final model with 6 components will be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the crime rate for the sample data is 1248\n",
      "[1] \"6-Component PCA Model\"\n",
      "\n",
      "Call:\n",
      "lm(formula = Crime ~ ., data = as.data.frame(pca_data[, c(1:6, \n",
      "    16)]))\n",
      "\n",
      "Residuals:\n",
      "    Min      1Q  Median      3Q     Max \n",
      "-377.15 -172.23   25.81  132.10  480.38 \n",
      "\n",
      "Coefficients:\n",
      "            Estimate Std. Error t value Pr(>|t|)    \n",
      "(Intercept)   905.09      35.35  25.604  < 2e-16 ***\n",
      "PC1            65.22      14.56   4.478 6.14e-05 ***\n",
      "PC2           -70.08      21.35  -3.283  0.00214 ** \n",
      "PC3            25.19      25.23   0.998  0.32409    \n",
      "PC4            69.45      33.14   2.095  0.04252 *  \n",
      "PC5          -229.04      36.50  -6.275 1.94e-07 ***\n",
      "PC6           -60.21      48.04  -1.253  0.21734    \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Residual standard error: 242.3 on 40 degrees of freedom\n",
      "Multiple R-squared:  0.6586,\tAdjusted R-squared:  0.6074 \n",
      "F-statistic: 12.86 on 6 and 40 DF,  p-value: 4.869e-08\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_6_comp <- lm(formula=Crime ~ ., data=as.data.frame(pca_data[, c(1:6, 16)]))\n",
    "\n",
    "# Transform the sample data into the same PCA vector space by first scaling the data\n",
    "# around the center and the same scale range used when transforming the original dataset.\n",
    "# Then multiply by the rotation.\n",
    "sample_data_transformed <- scale(sample_data, pca_crime$center, pca_crime$scale) %*% pca_crime$rotation\n",
    "\n",
    "sample_prediction_pca <- round(predict(model_6_comp, as.data.frame(t(sample_data_transformed[, 1:6]), 3)))\n",
    "\n",
    "print(glue(\"Prediction for the crime rate for the sample data is {sample_prediction_pca}\"))\n",
    "print(\"6-Component PCA Model\")\n",
    "print(summary(model_6_comp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adjusted R-squared was 0.6074 and the residual standard error was 242.3 which are both worse than the values for the model generated in question 8.2. Interestingly, the predicted crime rate was 1248 which was very similar to the 1285.283 value predicted by the model in question 8.2.\n",
    "\n",
    "This shows that the componenets generated by PCA are not the best predictors when predicting crime rate. Using the original predictors give better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10.1\n",
    "\n",
    "\n",
    "**Using the same crime data set uscrime.txt as in Questions 8.2 and 9.1, find the best model you can using**\n",
    "1. a regression tree model, and\n",
    "2. a random forest model.\n",
    "\n",
    "**In R, you can use the tree package or the rpart package, and the randomForest package. For each model, describe one or two qualitative takeaways you get from analyzing the results (i.e., don’t just stop when you have a good model, but interpret it too).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the regression tree model, I decided to use the rpart library to build the model. The original dataset without any feature selection was used. Also, the complexity parameter (CP) is used to prune the tree. The printcp() function shows the CP at each split in the tree.\n",
    "\n",
    "My understanding of what this function is doing is that the tree is built out completely and then the tree is then pruned by removing the splits in data one by one. As each split is being removed, the CP is calculated. The CP has a minimum threshold of 0.01 and if the next split does not improve the R^2 value by 0.01 then the model is finished.\n",
    "\n",
    "The model below ended up with 3 splits before hitting the 0.01 threshold value. At each split the cross-validated error (xerror) is calculated and the tree at which the minimum xerror is found is the optimal model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression tree:\n",
      "rpart(formula = Crime ~ ., data = crime_data, method = \"anova\")\n",
      "\n",
      "Variables actually used in tree construction:\n",
      "[1] NW  Po1 Pop\n",
      "\n",
      "Root node error: 6880928/47 = 146403\n",
      "\n",
      "n= 47 \n",
      "\n",
      "        CP nsplit rel error xerror    xstd\n",
      "1 0.362963      0   1.00000 1.0495 0.26921\n",
      "2 0.148143      1   0.63704 1.1724 0.24786\n",
      "3 0.051732      2   0.48889 1.2275 0.27769\n",
      "4 0.010000      3   0.43716 1.2019 0.27894\n"
     ]
    }
   ],
   "source": [
    "tree <- rpart(formula=Crime ~., method=\"anova\", data=crime_data)\n",
    "\n",
    "printcp(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, only the NW, Pol and Pop features were used in creating the tree model. The optimal model, surprisingly, is when there is no split in the data.. Excluding this case leaves the tree with one split to have the lowest xerror value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAAJYCAYAAABy5h8aAAAEGWlDQ1BrQ0dDb2xvclNwYWNl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\nZoQAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotcp(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plotcp() function above plots the cross-validated error against the CP values from the tree model as its being pruned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune the tree \n",
    "pfit<- prune(tree, cp=tree$cptable[which.min(tree$cptable[,\"xerror\"]),\"CP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression tree:\n",
      "rpart(formula = Crime ~ ., data = crime_data, method = \"anova\")\n",
      "\n",
      "Variables actually used in tree construction:\n",
      "character(0)\n",
      "\n",
      "Root node error: 6880928/47 = 146403\n",
      "\n",
      "n= 47 \n",
      "\n",
      "       CP nsplit rel error xerror    xstd\n",
      "1 0.36296      0         1 1.0495 0.26921\n"
     ]
    }
   ],
   "source": [
    "printcp(pfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruning the tree model so that the minimum xerror is used yields a single node with no split which is not very helpful.\n",
    "\n",
    "The takeaways from this exercise is that a single decision tree is not very good at predicting something complicated like crime rate. Even with more splits in the data, the cross-validated error did not decrease which means the variation in the data is not properly accounted for in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest algorithm was used with every predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Number: 1\n",
      "       IncNodePurity\n",
      "M          91177.621\n",
      "So          8420.084\n",
      "Ed        105862.182\n",
      "Po1       556680.976\n",
      "Po2       513041.557\n",
      "LF        125229.082\n",
      "M.F        67854.648\n",
      "Pop       432049.094\n",
      "NW        253423.385\n",
      "U1         90634.725\n",
      "U2         96753.300\n",
      "Wealth    408001.602\n",
      "Ineq      101494.754\n",
      "Prob      710772.143\n",
      "Time      283103.346\n",
      "Fold Number: 2\n",
      "       IncNodePurity\n",
      "M          183397.08\n",
      "So          20368.92\n",
      "Ed         193300.66\n",
      "Po1       1084819.76\n",
      "Po2        967155.71\n",
      "LF         344948.39\n",
      "M.F        264777.86\n",
      "Pop        320945.27\n",
      "NW         700732.17\n",
      "U1         109479.21\n",
      "U2         134470.84\n",
      "Wealth     530953.04\n",
      "Ineq       193848.47\n",
      "Prob       669296.24\n",
      "Time       178030.68\n",
      "Fold Number: 3\n",
      "       IncNodePurity\n",
      "M          186292.21\n",
      "So          19158.05\n",
      "Ed         145769.43\n",
      "Po1        905368.34\n",
      "Po2        873145.60\n",
      "LF         141066.78\n",
      "M.F        313657.72\n",
      "Pop        215304.27\n",
      "NW         268758.21\n",
      "U1          83337.07\n",
      "U2          91243.93\n",
      "Wealth     238473.49\n",
      "Ineq       142973.55\n",
      "Prob       475601.06\n",
      "Time        94612.52\n",
      "Fold Number: 4\n",
      "       IncNodePurity\n",
      "M           156631.6\n",
      "So           25960.6\n",
      "Ed          165800.3\n",
      "Po1        1167463.3\n",
      "Po2        1114705.9\n",
      "LF          166693.8\n",
      "M.F         196358.4\n",
      "Pop         173793.3\n",
      "NW          345801.2\n",
      "U1          113838.9\n",
      "U2          126682.8\n",
      "Wealth      754509.4\n",
      "Ineq        124079.3\n",
      "Prob        625023.0\n",
      "Time        159722.7\n",
      "Fold Number: 5\n",
      "       IncNodePurity\n",
      "M          151906.26\n",
      "So          15248.45\n",
      "Ed         218176.11\n",
      "Po1       1062797.14\n",
      "Po2       1056350.91\n",
      "LF         246356.17\n",
      "M.F        214079.08\n",
      "Pop        439809.10\n",
      "NW         396089.21\n",
      "U1         121920.63\n",
      "U2         338742.99\n",
      "Wealth     591686.08\n",
      "Ineq       207998.16\n",
      "Prob       594151.59\n",
      "Time       175687.24\n",
      "RMSE: 314.025\n",
      "MAE: 226.957\n"
     ]
    }
   ],
   "source": [
    "# Shuffle data\n",
    "shuffled_df <- crime_data[sample(nrow(crime_data)),]\n",
    "\n",
    "# 5 fold split\n",
    "folds <- cut(seq(1, nrow(crime_data)), breaks=5, labels=FALSE)\n",
    "\n",
    "# For each fold, train and test on RF algorithm\n",
    "resids <- c(1:nrow(crime_data))\n",
    "preds <- c(1:nrow(crime_data))\n",
    "for (i in 1:5) {\n",
    "    test_indices <- which(folds==i, arr.ind=TRUE)\n",
    "    test_data <- as.data.frame(shuffled_df[test_indices, ])\n",
    "    train_data <- as.data.frame(shuffled_df[-test_indices, ])\n",
    "\n",
    "    temp_fit <- randomForest(formula=Crime ~., data=train_data)\n",
    "\n",
    "    # Perform prediction step on test data since model was fit using the training data\n",
    "    preds[test_indices] <- predict(temp_fit, test_data)    \n",
    "    resids[test_indices] <- test_data$Crime - preds[test_indices]\n",
    "    \n",
    "    print(glue(\"Fold Number: {i}\"))\n",
    "    print(importance(temp_fit))\n",
    "}\n",
    "\n",
    "overall_rmse <- round(rmse(resids), 3)\n",
    "overall_mae <- round(mae(resids), 3)\n",
    "\n",
    "print(glue(\"RMSE: {overall_rmse}\"))\n",
    "print(glue(\"MAE: {overall_mae}\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE and the MAE are comparable to the model generated in question 9 using PCA and linear regression.\n",
    "\n",
    "Looking at the importance of each predictor for each k-fold step, the predictors that show up most frequently are police protection investment (Po1 and Po2), probability of being imprisoned (prob), and median wealth (Wealth). These make sense since economic stability affects police funding, which in turn probably affects the number of people being imprisoned.\n",
    "\n",
    "One thing I wish that random forest could show is the positive or negative correlation a predictor has with the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10.2\n",
    "\n",
    "**Describe a situation or problem from your job, everyday life, current events, etc., for which a logistic regression model would be appropriate. List some (up to 5) predictors that you might use.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "\n",
    "A situation where logistic regression might be useful in my everyday life is predicting the probability that I snooze my alarm in the morning before work. The 5 predictors that I might use to model this situation are:\n",
    "\n",
    "1. How many hours did I sleep last night?\n",
    "2. Is it the weekend or a weekday?\n",
    "3. Do I have a meeting I cannot be late for?\n",
    "4. Did I go out drinking last night?\n",
    "5. Was yesterday an especially tiring day?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10.3\n",
    "\n",
    "**1. Using the GermanCredit data set germancredit.txt from http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german / (description at http://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29 ), use logistic regression to find a good predictive model for whether credit applicants are good credit risks or not. Show your model (factors used and their coefficients), the software output, and the quality of fit. You can use the glm function in R. To get a logistic regression (logit) model on data where the response is either zero or one, use family=binomial(link=”logit”) in your glm function call.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "german_data <- read.table('../data//10.3germancreditSummer2018_numeric.txt', sep='', header=FALSE)\n",
    "german_data$V25 <- german_data$V25 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a 5-fold cross-validation, the logistic regression algorithm was implemented with every predictor. The summary of the model at each fold in the cross-validation step is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold number 1\n",
      "\n",
      "Call:\n",
      "glm(formula = V25 ~ ., family = binomial(link = \"logit\"), data = train_data)\n",
      "\n",
      "Deviance Residuals: \n",
      "    Min       1Q   Median       3Q      Max  \n",
      "-2.1716  -0.7298  -0.4182   0.8177   2.5710  \n",
      "\n",
      "Coefficients:\n",
      "             Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)  3.570281   1.343636   2.657 0.007880 ** \n",
      "V1          -0.538473   0.078591  -6.852  7.3e-12 ***\n",
      "V2           0.036298   0.009918   3.660 0.000252 ***\n",
      "V3          -0.320909   0.099566  -3.223 0.001268 ** \n",
      "V4           0.003639   0.004372   0.832 0.405160    \n",
      "V5          -0.184017   0.065455  -2.811 0.004933 ** \n",
      "V6          -0.168531   0.086785  -1.942 0.052145 .  \n",
      "V7          -0.246720   0.124642  -1.979 0.047768 *  \n",
      "V8          -0.009899   0.091469  -0.108 0.913817    \n",
      "V9           0.148272   0.109908   1.349 0.177321    \n",
      "V10         -0.018791   0.009674  -1.942 0.052083 .  \n",
      "V11         -0.333398   0.125977  -2.646 0.008133 ** \n",
      "V12          0.172163   0.193264   0.891 0.373027    \n",
      "V13          0.039297   0.268766   0.146 0.883754    \n",
      "V14         -0.221315   0.211779  -1.045 0.296009    \n",
      "V15         -1.366569   0.722074  -1.893 0.058416 .  \n",
      "V16          0.606539   0.213502   2.841 0.004499 ** \n",
      "V17         -0.955346   0.377364  -2.532 0.011353 *  \n",
      "V18          1.090891   0.464125   2.350 0.018752 *  \n",
      "V19          1.526622   0.606277   2.518 0.011801 *  \n",
      "V20          0.267503   0.408107   0.655 0.512163    \n",
      "V21         -0.174579   0.367848  -0.475 0.635075    \n",
      "V22         -0.807382   0.658500  -1.226 0.220164    \n",
      "V23         -0.091596   0.358584  -0.255 0.798385    \n",
      "V24         -0.113003   0.291557  -0.388 0.698323    \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "(Dispersion parameter for binomial family taken to be 1)\n",
      "\n",
      "    Null deviance: 984.07  on 799  degrees of freedom\n",
      "Residual deviance: 762.13  on 775  degrees of freedom\n",
      "AIC: 812.13\n",
      "\n",
      "Number of Fisher Scoring iterations: 5\n",
      "\n",
      "Fold number 2\n",
      "\n",
      "Call:\n",
      "glm(formula = V25 ~ ., family = binomial(link = \"logit\"), data = train_data)\n",
      "\n",
      "Deviance Residuals: \n",
      "    Min       1Q   Median       3Q      Max  \n",
      "-2.1186  -0.6809  -0.3879   0.7471   2.6178  \n",
      "\n",
      "Coefficients:\n",
      "             Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)  2.824790   1.324471   2.133 0.032944 *  \n",
      "V1          -0.672924   0.083585  -8.051 8.23e-16 ***\n",
      "V2           0.038095   0.009772   3.898 9.68e-05 ***\n",
      "V3          -0.428717   0.096960  -4.422 9.80e-06 ***\n",
      "V4           0.002328   0.004445   0.524 0.600440    \n",
      "V5          -0.245916   0.068246  -3.603 0.000314 ***\n",
      "V6          -0.098075   0.084987  -1.154 0.248500    \n",
      "V7          -0.219727   0.129357  -1.699 0.089392 .  \n",
      "V8           0.027609   0.094224   0.293 0.769511    \n",
      "V9           0.141688   0.112265   1.262 0.206916    \n",
      "V10         -0.001783   0.009852  -0.181 0.856353    \n",
      "V11         -0.312250   0.126303  -2.472 0.013427 *  \n",
      "V12          0.131410   0.180447   0.728 0.466462    \n",
      "V13          0.136850   0.264349   0.518 0.604675    \n",
      "V14         -0.349757   0.218278  -1.602 0.109079    \n",
      "V15         -1.181958   0.668007  -1.769 0.076830 .  \n",
      "V16          0.607704   0.218717   2.778 0.005461 ** \n",
      "V17         -0.733068   0.358053  -2.047 0.040622 *  \n",
      "V18          1.149912   0.455245   2.526 0.011540 *  \n",
      "V19          1.272696   0.645370   1.972 0.048605 *  \n",
      "V20          0.472985   0.406256   1.164 0.244322    \n",
      "V21         -0.090798   0.356498  -0.255 0.798960    \n",
      "V22         -0.316872   0.678792  -0.467 0.640630    \n",
      "V23         -0.055578   0.353234  -0.157 0.874976    \n",
      "V24          0.005350   0.289491   0.018 0.985255    \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "(Dispersion parameter for binomial family taken to be 1)\n",
      "\n",
      "    Null deviance: 972.25  on 799  degrees of freedom\n",
      "Residual deviance: 723.60  on 775  degrees of freedom\n",
      "AIC: 773.6\n",
      "\n",
      "Number of Fisher Scoring iterations: 5\n",
      "\n",
      "Fold number 3\n",
      "\n",
      "Call:\n",
      "glm(formula = V25 ~ ., family = binomial(link = \"logit\"), data = train_data)\n",
      "\n",
      "Deviance Residuals: \n",
      "    Min       1Q   Median       3Q      Max  \n",
      "-2.2406  -0.6978  -0.4007   0.7375   2.6816  \n",
      "\n",
      "Coefficients:\n",
      "             Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)  3.182748   1.288165   2.471  0.01348 *  \n",
      "V1          -0.598023   0.080007  -7.475 7.74e-14 ***\n",
      "V2           0.039576   0.009979   3.966 7.31e-05 ***\n",
      "V3          -0.367563   0.096968  -3.791  0.00015 ***\n",
      "V4           0.004779   0.004347   1.099  0.27166    \n",
      "V5          -0.231610   0.069359  -3.339  0.00084 ***\n",
      "V6          -0.146578   0.087138  -1.682  0.09254 .  \n",
      "V7          -0.215977   0.133412  -1.619  0.10548    \n",
      "V8          -0.005577   0.092102  -0.061  0.95171    \n",
      "V9           0.106497   0.114224   0.932  0.35116    \n",
      "V10         -0.008031   0.009893  -0.812  0.41695    \n",
      "V11         -0.273305   0.125516  -2.177  0.02945 *  \n",
      "V12          0.265954   0.181115   1.468  0.14199    \n",
      "V13          0.105416   0.268319   0.393  0.69441    \n",
      "V14         -0.294513   0.221854  -1.328  0.18434    \n",
      "V15         -1.176222   0.633404  -1.857  0.06331 .  \n",
      "V16          0.615190   0.219764   2.799  0.00512 ** \n",
      "V17         -1.339983   0.422687  -3.170  0.00152 ** \n",
      "V18          1.056840   0.460653   2.294  0.02178 *  \n",
      "V19          1.476987   0.627844   2.352  0.01865 *  \n",
      "V20         -0.094189   0.422387  -0.223  0.82354    \n",
      "V21         -0.356566   0.369183  -0.966  0.33413    \n",
      "V22         -0.965279   0.664249  -1.453  0.14617    \n",
      "V23         -0.148466   0.371885  -0.399  0.68973    \n",
      "V24         -0.177599   0.303494  -0.585  0.55843    \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "(Dispersion parameter for binomial family taken to be 1)\n",
      "\n",
      "    Null deviance: 972.25  on 799  degrees of freedom\n",
      "Residual deviance: 733.26  on 775  degrees of freedom\n",
      "AIC: 783.26\n",
      "\n",
      "Number of Fisher Scoring iterations: 5\n",
      "\n",
      "Fold number 4\n",
      "\n",
      "Call:\n",
      "glm(formula = V25 ~ ., family = binomial(link = \"logit\"), data = train_data)\n",
      "\n",
      "Deviance Residuals: \n",
      "    Min       1Q   Median       3Q      Max  \n",
      "-2.1284  -0.7160  -0.4293   0.7784   2.5806  \n",
      "\n",
      "Coefficients:\n",
      "             Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)  3.007958   1.334627   2.254 0.024210 *  \n",
      "V1          -0.535891   0.080714  -6.639 3.15e-11 ***\n",
      "V2           0.031192   0.009310   3.350 0.000807 ***\n",
      "V3          -0.401864   0.097910  -4.104 4.05e-05 ***\n",
      "V4           0.004642   0.004089   1.135 0.256218    \n",
      "V5          -0.206121   0.065974  -3.124 0.001783 ** \n",
      "V6          -0.158269   0.084010  -1.884 0.059575 .  \n",
      "V7          -0.143882   0.130888  -1.099 0.271650    \n",
      "V8           0.016962   0.092432   0.184 0.854396    \n",
      "V9           0.193243   0.111983   1.726 0.084412 .  \n",
      "V10         -0.008548   0.009222  -0.927 0.353979    \n",
      "V11         -0.308757   0.122110  -2.529 0.011455 *  \n",
      "V12          0.261923   0.176513   1.484 0.137842    \n",
      "V13          0.013331   0.256113   0.052 0.958486    \n",
      "V14         -0.157867   0.211424  -0.747 0.455253    \n",
      "V15         -1.690419   0.691375  -2.445 0.014485 *  \n",
      "V16          0.679038   0.218811   3.103 0.001914 ** \n",
      "V17         -0.865764   0.379802  -2.280 0.022637 *  \n",
      "V18          0.670760   0.464135   1.445 0.148406    \n",
      "V19          1.134520   0.621714   1.825 0.068027 .  \n",
      "V20          0.568704   0.393079   1.447 0.147955    \n",
      "V21          0.070850   0.348357   0.203 0.838835    \n",
      "V22         -0.302046   0.679323  -0.445 0.656588    \n",
      "V23          0.119608   0.351353   0.340 0.733539    \n",
      "V24          0.031114   0.288309   0.108 0.914060    \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "(Dispersion parameter for binomial family taken to be 1)\n",
      "\n",
      "    Null deviance: 963.44  on 799  degrees of freedom\n",
      "Residual deviance: 753.12  on 775  degrees of freedom\n",
      "AIC: 803.12\n",
      "\n",
      "Number of Fisher Scoring iterations: 5\n",
      "\n",
      "Fold number 5\n",
      "\n",
      "Call:\n",
      "glm(formula = V25 ~ ., family = binomial(link = \"logit\"), data = train_data)\n",
      "\n",
      "Deviance Residuals: \n",
      "    Min       1Q   Median       3Q      Max  \n",
      "-2.2420  -0.7161  -0.4024   0.7628   2.6580  \n",
      "\n",
      "Coefficients:\n",
      "             Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)  3.635328   1.324215   2.745 0.006046 ** \n",
      "V1          -0.552613   0.077867  -7.097 1.28e-12 ***\n",
      "V2           0.028769   0.009507   3.026 0.002477 ** \n",
      "V3          -0.355426   0.099108  -3.586 0.000335 ***\n",
      "V4           0.005916   0.004179   1.416 0.156866    \n",
      "V5          -0.264647   0.066250  -3.995 6.48e-05 ***\n",
      "V6          -0.166318   0.083577  -1.990 0.046591 *  \n",
      "V7          -0.230813   0.129834  -1.778 0.075444 .  \n",
      "V8           0.016800   0.091208   0.184 0.853861    \n",
      "V9           0.259941   0.110766   2.347 0.018938 *  \n",
      "V10         -0.009812   0.009203  -1.066 0.286345    \n",
      "V11         -0.349849   0.123767  -2.827 0.004703 ** \n",
      "V12          0.203383   0.182256   1.116 0.264457    \n",
      "V13          0.189689   0.263675   0.719 0.471891    \n",
      "V14         -0.377618   0.216551  -1.744 0.081197 .  \n",
      "V15         -1.861453   0.694944  -2.679 0.007394 ** \n",
      "V16          0.773128   0.220812   3.501 0.000463 ***\n",
      "V17         -0.908548   0.369684  -2.458 0.013986 *  \n",
      "V18          1.183299   0.489472   2.418 0.015627 *  \n",
      "V19          1.365786   0.638255   2.140 0.032365 *  \n",
      "V20          0.379289   0.402723   0.942 0.346289    \n",
      "V21         -0.136162   0.352023  -0.387 0.698906    \n",
      "V22         -0.671381   0.711973  -0.943 0.345688    \n",
      "V23         -0.130295   0.362669  -0.359 0.719396    \n",
      "V24         -0.013896   0.283952  -0.049 0.960970    \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "(Dispersion parameter for binomial family taken to be 1)\n",
      "\n",
      "    Null deviance: 993.74  on 799  degrees of freedom\n",
      "Residual deviance: 748.09  on 775  degrees of freedom\n",
      "AIC: 798.09\n",
      "\n",
      "Number of Fisher Scoring iterations: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Shuffle data\n",
    "shuffled_df <- german_data[sample(nrow(german_data)),]\n",
    "\n",
    "# 5 fold split\n",
    "folds <- cut(seq(1, nrow(german_data)), breaks=5, labels=FALSE)\n",
    "\n",
    "# For each fold, train and test on Linear Regression algorithm\n",
    "resids <- c(1:nrow(german_data))\n",
    "preds <- c(1:nrow(german_data))\n",
    "for (i in 1:5) {\n",
    "    test_indices <- which(folds==i, arr.ind=TRUE)\n",
    "    test_data <- as.data.frame(shuffled_df[test_indices, ])\n",
    "    train_data <- as.data.frame(shuffled_df[-test_indices, ])\n",
    "\n",
    "    temp_fit <- glm(V25 ~., family=binomial(link='logit'), data=train_data)\n",
    "\n",
    "    # Perform prediction step on test data since model was fit using the training data\n",
    "    preds[test_indices] <- predict(temp_fit, newdata=test_data, type='response')\n",
    "    print(glue(\"Fold number {i}\"))\n",
    "    print(summary(temp_fit))\n",
    "}\n",
    "\n",
    "binary_preds <- ifelse(preds > 0.5,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training and validation step, the final model using all available data is built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "glm(formula = V25 ~ ., family = binomial(link = \"logit\"), data = german_data)\n",
      "\n",
      "Deviance Residuals: \n",
      "    Min       1Q   Median       3Q      Max  \n",
      "-2.1675  -0.7082  -0.4129   0.7890   2.6220  \n",
      "\n",
      "Coefficients:\n",
      "             Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)  3.231152   1.171518   2.758 0.005814 ** \n",
      "V1          -0.575461   0.071065  -8.098 5.60e-16 ***\n",
      "V2           0.034089   0.008587   3.970 7.20e-05 ***\n",
      "V3          -0.373500   0.086952  -4.295 1.74e-05 ***\n",
      "V4           0.004294   0.003801   1.130 0.258535    \n",
      "V5          -0.225906   0.059604  -3.790 0.000151 ***\n",
      "V6          -0.145873   0.075689  -1.927 0.053945 .  \n",
      "V7          -0.211760   0.114816  -1.844 0.065132 .  \n",
      "V8           0.011961   0.081916   0.146 0.883906    \n",
      "V9           0.167814   0.099152   1.692 0.090552 .  \n",
      "V10         -0.009432   0.008478  -1.112 0.265925    \n",
      "V11         -0.313985   0.110500  -2.841 0.004490 ** \n",
      "V12          0.208317   0.161724   1.288 0.197710    \n",
      "V13          0.084091   0.234396   0.359 0.719778    \n",
      "V14         -0.271055   0.191837  -1.413 0.157674    \n",
      "V15         -1.442590   0.604540  -2.386 0.017021 *  \n",
      "V16          0.649688   0.193702   3.354 0.000796 ***\n",
      "V17         -0.950668   0.336940  -2.821 0.004780 ** \n",
      "V18          1.019901   0.414228   2.462 0.013810 *  \n",
      "V19          1.337142   0.556082   2.405 0.016191 *  \n",
      "V20          0.318564   0.359882   0.885 0.376053    \n",
      "V21         -0.132711   0.317574  -0.418 0.676028    \n",
      "V22         -0.594921   0.602898  -0.987 0.323756    \n",
      "V23         -0.063827   0.319117  -0.200 0.841473    \n",
      "V24         -0.050021   0.258695  -0.193 0.846678    \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "(Dispersion parameter for binomial family taken to be 1)\n",
      "\n",
      "    Null deviance: 1221.73  on 999  degrees of freedom\n",
      "Residual deviance:  935.33  on 975  degrees of freedom\n",
      "AIC: 985.33\n",
      "\n",
      "Number of Fisher Scoring iterations: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_model <- glm(V25 ~., family=binomial(link='logit'), data=german_data)\n",
    "\n",
    "# Perform prediction step on test data since model was fit using the training data\n",
    "final_preds <- predict(final_model, newdata=german_data, type='response')\n",
    "print(summary(final_model))\n",
    "\n",
    "binary_final_preds <- ifelse(final_preds > 0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   0   1\n",
       "         0 629 144\n",
       "         1  71 156\n",
       "                                          \n",
       "               Accuracy : 0.785           \n",
       "                 95% CI : (0.7582, 0.8101)\n",
       "    No Information Rate : 0.7             \n",
       "    P-Value [Acc > NIR] : 9.063e-10       \n",
       "                                          \n",
       "                  Kappa : 0.4498          \n",
       " Mcnemar's Test P-Value : 9.091e-07       \n",
       "                                          \n",
       "            Sensitivity : 0.8986          \n",
       "            Specificity : 0.5200          \n",
       "         Pos Pred Value : 0.8137          \n",
       "         Neg Pred Value : 0.6872          \n",
       "             Prevalence : 0.7000          \n",
       "         Detection Rate : 0.6290          \n",
       "   Detection Prevalence : 0.7730          \n",
       "      Balanced Accuracy : 0.7093          \n",
       "                                          \n",
       "       'Positive' Class : 0               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(data = as.factor(binary_final_preds), as.factor(german_data$V25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall accuracy of the model is 78.5% and the most important predictors seem to be status of existing checking account, credit history, and credit amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Because the model gives a result between 0 and 1, it requires setting a threshold probability to separate between “good” and “bad” answers. In this data set, they estimate that incorrectly identifying a bad customer as good, is 5 times worse than incorrectly classifying a good customer as bad. Determine a good threshold probability based on your model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the confusion matrix above, there are 71 data points being misclassified as \"bad\" credit risks when they're actually \"good\" credit risks and 144 data points being misclassified as \"good\" credit risks when they're actually \"bad\" credit risks. So, the cost for this model becomes:\n",
    "\n",
    "Cost = 71 x 1 + 144 x 5 = 791\n",
    "\n",
    "I want to minimize this by removing as many false positives as possible without putting too many people into the false negative category. **Its important to note that the positive class is 0 in this case. This means I need a lower threshold value in order for a person to be classified as a \"good\" credit risk. If the positive class was 1 then I would need a higher threshold value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   0   1\n",
       "         0 412  45\n",
       "         1 288 255\n",
       "                                          \n",
       "               Accuracy : 0.667           \n",
       "                 95% CI : (0.6368, 0.6962)\n",
       "    No Information Rate : 0.7             \n",
       "    P-Value [Acc > NIR] : 0.9891          \n",
       "                                          \n",
       "                  Kappa : 0.3561          \n",
       " Mcnemar's Test P-Value : <2e-16          \n",
       "                                          \n",
       "            Sensitivity : 0.5886          \n",
       "            Specificity : 0.8500          \n",
       "         Pos Pred Value : 0.9015          \n",
       "         Neg Pred Value : 0.4696          \n",
       "             Prevalence : 0.7000          \n",
       "         Detection Rate : 0.4120          \n",
       "   Detection Prevalence : 0.4570          \n",
       "      Balanced Accuracy : 0.7193          \n",
       "                                          \n",
       "       'Positive' Class : 0               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_preds <- ifelse(final_preds > 0.2,1,0)\n",
    "confusionMatrix(data = as.factor(new_preds), as.factor(german_data$V25))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "With a threshold of 0.2, I got 45 false positives and 288 false negatives for a cost of 513, which is more than 35% lower than the cost at a 0.5 threshold. However, its important to note that the number of true positives goes down *significantly* from 629 to 412 users. This is critical because if I keep increasing the threshold lower and lower, then the cost may decrease but I may end up having no users that are correctly predicted to be a \"good\" credit risk."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
